######################################################################################88

from collections import Counter
from glob import glob
import pandas as pd
import numpy as np
import design_paths
import design_stats
design_paths.setup_import_paths()
import tcrdock as td2
from tcrdock.tcrdist.amino_acids import amino_acids
from os import system, mkdir, remove, makedirs
from os.path import exists, basename, dirname
import itertools as it
import json
import random
import sys
from sys import exit
import copy
from collections import OrderedDict

from design_stats import get_designable_positions


mpnn_mod_seq_map = {
    's': 'E', # SEP --> GLU
}

def map_sequence_with_mods_for_mpnn(seq):
    newseq = ''.join(mpnn_mod_seq_map.get(x,x) for x in seq)
    assert newseq.isupper()
    return newseq


def setup_for_protein_mpnn(
        pose,
        design_mask,
        idstring, # like a pdbid, for example
        alternate_chainseq = None,
):
    ''' returns 3 dicts: parsed_chains, assigned_chains, fixed_positions
    '''

    # which chains are designable?
    #
    # assigned_chains looks like:
    #{"4YOW": [["A", "C"], ["B", "D", "E", "F"]], "3HTN": [["A", "C"], ["B"]]}
    #
    # fixed_positions looks like: (these are 1-indexed)
    #{"4YOW": {"A": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,...
    #
    nres = len(pose['resids'])
    assert len(design_mask) == nres # list or array of True,False
    design_chains = sorted(set(r[0] for r,m in zip(pose['resids'], design_mask) if m))
    fixed_chains = sorted(set(c for c in pose['chains'] if c not in design_chains))

    assigned_chains = {idstring: [design_chains, fixed_chains]}

    fixed = {x:[] for x in pose['chains']}
    res_count = Counter()
    for r, m in zip(pose['resids'], design_mask):
        ch = r[0]
        res_count[ch] += 1
        if not m: # fixed
            fixed[ch].append(res_count[ch]) # 1-indexed!

    fixed_positions = {idstring:fixed}

    parsed_chains = {}
    if alternate_chainseq is None:
        cs = pose['chainseq'].split('/')
    else:
        assert len(alternate_chainseq) == len(pose['chainseq'])
        cs = alternate_chainseq.split('/')
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs)) # debug
        assert chainbounds == list(pose['chainbounds'])

    old_cs = cs
    cs = [map_sequence_with_mods_for_mpnn(x) for x in cs]
    if old_cs != cs:
        print('wrapper_tools::setup_for_protein_mpnn cs has mods:',
              [(ii, x,'-->',y) for ii, (x,y) in enumerate(zip(old_cs, cs)) if x!=y])

    atoms = [' N  ', ' CA ', ' C  ', ' O  ']

    for chain, seq in zip(pose['chains'], cs):
        parsed_chains['seq_chain_'+chain] = seq
        coords = {}
        for atom in atoms:
            xyzs = []
            nans = np.full(3,np.nan)
            for r in pose['resids']:
                if r[0] == chain:
                    xyzs.append(pose['coords'][r].get(atom, nans).tolist())
            coords[f'{atom.strip()}_chain_{chain}'] = xyzs
        parsed_chains['coords_chain_'+chain] = coords
    parsed_chains['name'] = idstring
    parsed_chains['num_of_chains'] = len(pose['chains'])
    parsed_chains['seq'] = ''.join(cs)


    return parsed_chains, assigned_chains, fixed_positions

def run_alphafold(
        targets,
        outprefix,
        num_recycle = 1,
        model_name = 'model_2_ptm', # want PAEs
        model_params_file = None,
        dry_run = False,
        ignore_identities = False,
):
    ''' Returns results df
    results are generated by predict_tcr_from_template_alignments.py, the
    *_final.tsv file  WITH EXTRA COLUMNS:

    model_pdbfile
    model_plddtfile
    model_paefile
    '''
    PY = design_paths.AF2_PYTHON
    EXE = design_paths.path_to_design_scripts / 'af2_wrapper.py'

    outfile = outprefix+'_targets.tsv'
    targets.to_csv(outfile, sep='\t', index=False)

    xargs = (f' --num_recycle {num_recycle} --model_names {model_name} ')
    if model_params_file is not None:
        xargs += f' --model_params_files {model_params_file} '
    if ignore_identities:
        xargs += ' --ignore_identities '
    cmd = (f'{PY} {EXE} {xargs} --targets {outfile} --outfile_prefix {outprefix} '
           f' > {outprefix}_run.log 2> {outprefix}_run.err')

    print(cmd, flush=True)
    if not dry_run:
        system(cmd)

    resultsfile = outprefix+'_final.tsv'
    assert exists(resultsfile), 'run_alphafold failed '+outprefix

    dfl = []
    for _,l in pd.read_table(resultsfile).iterrows():
        outl = l.copy()
        pdbfile = l[model_name+'_pdb_file']
        plddtfile = l[model_name+'_plddt_file']
        paefile   = l[model_name+'_predicted_aligned_error_file']
        assert exists(pdbfile) and exists(paefile)
        outl['model_pdbfile'] = pdbfile
        outl['model_plddtfile'] = plddtfile
        outl['model_paefile'] = paefile
        dfl.append(outl)

    return pd.DataFrame(dfl)


def make_new_mpnn_chainseq(
        mpnn_seq,
        old_chainseq,
        chainseq_ordered_chains,
        design_mask,
):
    ''' mpnn_seq is a '/'-separated string, with the new full sequence of each
    (partially) redesigned chain
    '''
    cs = old_chainseq.split('/')
    chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
    residue_chains = []
    for start,stop,chain in zip(chainbounds, chainbounds[1:], chainseq_ordered_chains):
        residue_chains.extend([chain]*(stop-start))
    assert (len(residue_chains) == len(old_chainseq.replace('/','')) ==
            len(design_mask))
    designable_chains = sorted(set([x for x,m in zip(residue_chains, design_mask)
                                    if m]))

    new_seqs = mpnn_seq.split('/')
    assert len(new_seqs) == len(designable_chains)

    for seq, chain in zip(new_seqs, designable_chains):
        ind = chainseq_ordered_chains.index(chain)
        assert len(seq) == len(cs[ind])
        cs[ind] = seq

    return '/'.join(cs)


def make_new_mpnn_chainseq_bad(
        mpnn_seq,
        old_chainseq,
        design_mask = None, # for debugging
):
    ''' mpnn_seq is a '/'-separated string, with the new full sequence of each
    (partially) redesigned chain
    '''
    new_seqs = mpnn_seq.split('/')
    def seq_match_score(seq1, seq2):
        return 100*abs(len(seq1)-len(seq2)) + sum(x!=y for x,y in zip(seq1,seq2))

    cs = old_chainseq.split('/')

    for new_seq in new_seqs:
        ch = min(enumerate(cs), key=lambda x:seq_match_score(x[1], new_seq))[0]
        old_seq = cs[ch]
        assert len(old_seq) == len(new_seq)
        if design_mask is not None: # debugging
            chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
            start = chainbounds[ch]
            assert all(((a==b) or c)
                       for a,b,c in zip(old_seq, new_seq, design_mask[start:]))
        cs[ch] = new_seq

    return '/'.join(cs)


def run_mpnn_peptide_probs(
        targets,
        outprefix,
        num_mpnn_seqs=3,
        constant_seed=None,
        dry_run=False,
        #verbose=False,
        sampling_temp=1.0,
        require_unique_targetids=False,
        ignore_pose_sequence=False,
        only_full_probs=False,
):
    ''' Returns results df

    targets has to have the columns below

    assumes that chain -3 is the peptide, and that num_chains in [4,5]

    '''
    required_cols = 'targetid chainseq model_pdbfile'.split()
    for col in required_cols:
        assert col in targets.columns

    if targets.targetid.value_counts().max()>1:
        assert not require_unique_targetids
        targets = targets.copy()
        targets['targetid'] = [f'{x}_{i}' for i,x in enumerate(targets.targetid)]

    # need one of these to figure out which positions are designable
    # I don't think this is true!
    #assert ('template_0_target_to_template_alignstring' in targets.columns or
    #        'designable_positions' in targets.columns)

    outdir = outprefix+'_mpnn/'
    if not exists(outdir):
        mkdir(outdir)

    parsed_chains, assigned_chains, fixed_positions = [], {}, {}

    for l in targets.itertuples():
        # note that if ignore_pose_sequence==True, l.chainseq may not match
        #  pose['chainseq']
        nres = len(l.chainseq.replace('/',''))
        cs = l.chainseq.split('/')
        nchains = len(cs)
        assert nchains in [4,5]
        peptide = cs[-3]
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
        design_mask = np.full((nres,), False)
        pep_posl = np.arange(chainbounds[-4], chainbounds[-3])
        assert len(pep_posl) == len(peptide) # sanity check
        design_mask[pep_posl] = True
        pose = td2.pdblite.pose_from_pdb(l.model_pdbfile)
        if not ignore_pose_sequence:
            assert pose['sequence'] == ''.join(cs)
        pose = td2.pdblite.set_chainbounds_and_renumber(pose, chainbounds)
        assert len(pose['sequence']) == nres

        pc, ac, fp = setup_for_protein_mpnn(
            pose, design_mask, l.targetid+'_full', alternate_chainseq=l.chainseq)
        parsed_chains.append(pc)
        assigned_chains.update(ac)
        fixed_positions.update(fp)

        if only_full_probs:
            continue

        # just the pmhc pose
        nres_pmhc = chainbounds[-3]
        pose = td2.pdblite.delete_chains(pose, [nchains-2, nchains-1])
        design_mask = design_mask[:nres_pmhc]

        pc, ac, fp = setup_for_protein_mpnn(
            pose, design_mask, l.targetid+'_pmhc', alternate_chainseq='/'.join(cs[:-2]))
        parsed_chains.append(pc)
        assigned_chains.update(ac)
        fixed_positions.update(fp)

        # just the peptide pose
        pose = td2.pdblite.delete_chains(pose, list(range(nchains-3)))
        assert pose['sequence'] == peptide
        design_mask = np.ones((len(peptide),), dtype=bool)

        pc, ac, fp = setup_for_protein_mpnn(pose, design_mask, l.targetid+'_peptide',
                                            alternate_chainseq=peptide)
        parsed_chains.append(pc)
        assigned_chains.update(ac)
        fixed_positions.update(fp)

    assigned_chains = [assigned_chains]
    fixed_positions = [fixed_positions]

    for vals, tag in zip([parsed_chains, assigned_chains, fixed_positions],
                         ['pc','ac','fp']):
        outfile = f'{outprefix}_{tag}.jsonl'
        with open(outfile,'w') as f:
            for val in vals:
                f.write(json.dumps(val) + '\n')

    seedarg = '' if constant_seed is None else f' --seed {constant_seed} '

    cmd = (f'{design_paths.MPNN_PYTHON} {design_paths.MPNN_SCRIPT} '
           f' --jsonl_path            {outprefix}_pc.jsonl '
           f' --chain_id_jsonl        {outprefix}_ac.jsonl '
           f' --fixed_positions_jsonl {outprefix}_fp.jsonl '
           f' --out_folder {outdir} --num_seq_per_target {num_mpnn_seqs} '
           f' --sampling_temp "{sampling_temp}" '
           f' --conditional_probs_only 1 '
           f' {seedarg} --batch_size 1 > {outprefix}_run.log '
           f' 2> {outprefix}_run.err')
    print(cmd, flush=True)
    if not dry_run:
        system(cmd)

    # now setup new targets array with redesigned sequences
    dfl = []
    for _, l in targets.iterrows():
        nres = len(l.chainseq.replace('/',''))
        cs = l.chainseq.split('/')
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))

        design_mask = np.full((nres,), False)
        pep_posl = np.arange(chainbounds[-4], chainbounds[-3])
        peplen = len(pep_posl)
        design_mask[pep_posl] = True

        peptide = cs[-3]
        assert peplen == len(peptide)
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))

        outl = l.copy()

        for suf in '_full _pmhc _peptide'.split():
            if only_full_probs and suf != '_full':
                continue

            resfile = f'{outdir}/conditional_probs_only/{l.targetid}{suf}.npz'
            assert exists(resfile)
            res = np.load(resfile)

            nres_suf = (nres if suf == '_full' else
                        len(peptide) if suf=='_peptide' else
                        chainbounds[-3])

            # res['mask'] is all 1.0's
            log_probs, S, design_mask = res['log_p'], res['S'], res['design_mask']
            assert log_probs.shape == (num_mpnn_seqs, nres_suf, 21)
            assert abs(res['design_mask'].sum() - peplen) < 1e-3

            pep_probs = np.exp(log_probs)[:,:peplen].mean(axis=0)
            assert pep_probs.shape == (peplen, 21)

            wt_ipepseq = S[:peplen]
            assert peptide == ''.join(amino_acids[x] for x in wt_ipepseq)

            wt_pep_probs = pep_probs[np.arange(peplen), wt_ipepseq]

            outl['wt_pep_logprobs'+suf] = ','.join(f'{np.log(x):.3f}'
                                                   for x in wt_pep_probs)
            outl['all_pep_logprobs'+suf] = ','.join(f'{np.log(x):.3f}'
                                                    for x in pep_probs.ravel())
            outl['total_wt_pep_prob'+suf] = sum(wt_pep_probs)
            outl['core_wt_pep_prob'+suf] = sum(wt_pep_probs[2:-1])

        outl['sampling_temp'] = sampling_temp
        if not only_full_probs:
            outl['pepspec_delta'] = (outl.total_wt_pep_prob_full -
                                     outl.total_wt_pep_prob_pmhc)

        dfl.append(outl)

    targets = pd.DataFrame(dfl)
    return targets # same as starting targets except with probs

def rank_chainseqs_by_peptide_probs(
        row,
        chainseqs,
        outprefix,
):
    dfl = []
    for ii, chainseq in enumerate(chainseqs):
        outl = row.copy()
        outl['chainseq'] = chainseq
        outl['targetid'] = f'{row.targetid}_cs_{ii}'
        dfl.append(outl)

    targets = pd.DataFrame(dfl)
    results = run_mpnn_peptide_probs(
        targets, outprefix, require_unique_targetids=True, ignore_pose_sequence=True,
        only_full_probs=True,
    )
    return sorted(zip(results.total_wt_pep_prob_full, results.chainseq), reverse=True)


def run_mpnn(
        targets,
        outprefix,
        num_mpnn_seqs=3,
        extend_flex=1,
        constant_seed=None,
        dry_run=False,
        sort_by_strength=False,
        sort_by_peptide_probs=False,
        sort_by_mpnn_score=False,
        pepspec_optimize = False,
        pepspec_weight = 20.0, # unused unless pepspec_optimize==True
        verbose=False,
        unbuffered=False,
        save_sorted_chainseqs=False,
        use_soluble_model = False,
        omit_AAs = None,
        AA_bias = None,
        new_mpnn = False,
        ignore_pose_sequence = False,
        model_checkpoint = None,
):
    ''' Returns results df

    targets has to have the columns below

    '''
    required_cols = 'targetid chainseq model_pdbfile'.split()
    for col in required_cols:
        assert col in targets.columns, f'Need column: {col}'

    assert targets.targetid.value_counts().max()==1 # no dups allowed
    assert not (sort_by_strength and sort_by_peptide_probs)

    # need one of these to figure out which positions are designable
    assert ('template_0_target_to_template_alignstring' in targets.columns or
            'designable_positions' in targets.columns)

    if use_soluble_model:
        new_mpnn = True

    SCRIPT = (design_paths.SPEC_MPNN_SCRIPT if pepspec_optimize else
              design_paths.NEW_MPNN_SCRIPT if new_mpnn else
              design_paths.MPNN_SCRIPT)

    outdir = outprefix+'_mpnn/'
    if not exists(outdir):
        mkdir(outdir)

    parsed_chains, assigned_chains, fixed_positions, spec_positions = [], {}, {}, {}

    all_chainseq_ordered_chains = {}
    for l in targets.itertuples():
        nres = len(l.chainseq.replace('/',''))
        flex_posl = get_designable_positions(row=l, extend_flex=extend_flex)
        design_mask = np.full((nres,), False)
        design_mask[flex_posl] = True

        cs = l.chainseq.split('/')
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
        pose = td2.pdblite.pose_from_pdb(l.model_pdbfile)
        if not ignore_pose_sequence:
            assert pose['sequence'] == ''.join(cs)
        pose = td2.pdblite.set_chainbounds_and_renumber(pose, chainbounds)
        assert len(pose['sequence']) == nres
        all_chainseq_ordered_chains[l.targetid] = pose['chains']

        pc, ac, fp = setup_for_protein_mpnn(pose, design_mask, l.targetid,
                                            alternate_chainseq=l.chainseq)
        parsed_chains.append(pc)
        assigned_chains.update(ac)
        fixed_positions.update(fp)

        if pepspec_optimize:
            peplen = len(cs[-3])
            if len(cs)==4: # class I
                spec_positions[l.targetid] = { # just the peptide
                    'A':[], 'B':list(range(1,peplen+1)), 'C':[], 'D':[]}
            else:
                assert len(cs) == 5
                spec_positions[l.targetid] = { # just the peptide
                    'A':[], 'B': [], 'C':list(range(1,peplen+1)), 'D':[], 'E':[]}


    assigned_chains = [assigned_chains]
    fixed_positions = [fixed_positions]
    spec_positions = [spec_positions]

    for vals,tag in zip([parsed_chains,assigned_chains,fixed_positions,spec_positions],
                        ['pc','ac','fp','sp']):
        outfile = f'{outprefix}_{tag}.jsonl'
        with open(outfile,'w') as f:
            for val in vals:
                f.write(json.dumps(val) + '\n')

    xargs = ''
    if use_soluble_model:
        xargs += ' --use_soluble_model '

    if AA_bias:
        outfile = f'{outprefix}_AA_bias.jsonl'
        with open(outfile,'w') as f:
            f.write(json.dumps(AA_bias) + '\n')
        xargs += f' --bias_AA_jsonl {outfile} '

    if model_checkpoint is not None:
        assert exists(model_checkpoint)
        assert model_checkpoint[0] == '/' and model_checkpoint.endswith('.pt')
        
        xargs += (f' --path_to_model_weights {dirname(model_checkpoint)} '
                  f' --model_name {basename(model_checkpoint)[:-3]} ') # drop .pt

    if omit_AAs is not None:
        assert type(omit_AAs) is list
        omit_AAs = ''.join(omit_AAs)
        xargs += f' --omit_AAs "{omit_AAs}" '

    if pepspec_optimize:
        xargs += (f' --spec_positions_jsonl {outprefix}_sp.jsonl '
                  f' --spec_weight {pepspec_weight} ')

    if constant_seed is not None:
        xargs += f' --seed {constant_seed} '

    uarg = ' -u ' if unbuffered else ''

    cmd = (f'{design_paths.MPNN_PYTHON} {uarg} {SCRIPT} {xargs} '
           f' --jsonl_path            {outprefix}_pc.jsonl '
           f' --chain_id_jsonl        {outprefix}_ac.jsonl '
           f' --fixed_positions_jsonl {outprefix}_fp.jsonl '
           f' --out_folder {outdir} --num_seq_per_target {num_mpnn_seqs} '
           f' --sampling_temp "0.1" '
           f' --batch_size 1 > {outprefix}_run.log '
           f' 2> {outprefix}_run.err')
    print(cmd, flush=True)
    if not dry_run:
        system(cmd)

    def get_variable_seq(chainseq, design_mask):
        'debugging'
        seq = ''
        for i,a in enumerate(chainseq):
            if a=='/':
                seq += '/'
            elif design_mask[i-chainseq[:i].count('/')]:
                seq += a
        return seq.strip('/')

    # now setup new targets array with redesigned sequences
    dfl = []
    for _, l in targets.iterrows():
        nres = len(l.chainseq.replace('/',''))
        flex_posl = get_designable_positions(row=l, extend_flex=extend_flex)
        design_mask = np.full((nres,), False)
        design_mask[flex_posl] = True
        cs = l.chainseq.split('/')
        old_fullseq = ''.join(cs)
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))

        fastafile = f'{outdir}/seqs/{l.targetid}.fa'
        with open(fastafile,'r') as f:
            fasta = f.read()
        seqs = [x for x in fasta.split('\n') if x and x[0] != '>'][1:]
        chains = all_chainseq_ordered_chains[l.targetid]
        chainseqs = [make_new_mpnn_chainseq(x, l.chainseq, chains, design_mask)
                     for x in seqs]
        headers = [x for x in fasta.split('\n') if x and x[0] == '>'][1:]
        assert all(x.split()[2].startswith('score=') and x.split()[2][-1]==','
                   for x in headers)
        mpnn_scores = [float(x.split()[2][6:-1])  for x in headers]
        assert len(seqs) == num_mpnn_seqs
        if sort_by_peptide_probs:
            sorted_chainseqs = rank_chainseqs_by_peptide_probs(
                l, chainseqs, outprefix+'pprobs')
        elif sort_by_strength: # lower strength is better
            sorted_chainseqs = sorted([(design_stats.get_total_strength(x), x)
                                       for x in chainseqs])
        elif sort_by_mpnn_score: # lower scores are better
            sorted_chainseqs = sorted(zip(mpnn_scores, chainseqs))
        else:
            # could easily sort by mpnn score to break ties here (now it's random)
            seq_counts = Counter(chainseqs)
            sorted_chainseqs = sorted([(seq_counts[x]+0.01*random.random(), x)
                                       for x in chainseqs], reverse=True)
        if verbose:
            for f, s in sorted_chainseqs:
                print(f'sorted_chainseqs {f:.6f} {get_variable_seq(s, design_mask)}')
        best_score, best_chainseq = sorted_chainseqs[0]
        cs = best_chainseq.split('/')

        new_fullseq = ''.join(cs)
        outl = l.copy()
        outl['chainseq'] = best_chainseq
        outl['mpnn_sorting_score'] = best_score

        ## update cdr3 information in the output row
        if hasattr(l, 'cdr3a'):
            assert old_fullseq.count(l.cdr3a) == 1
            start = old_fullseq.index(l.cdr3a)
            new_cdr3a = new_fullseq[start:start+len(l.cdr3a)]
            outl['cdr3a'] = new_cdr3a

            assert old_fullseq.count(l.cdr3b) == 1
            start = old_fullseq.index(l.cdr3b)
            new_cdr3b = new_fullseq[start:start+len(l.cdr3b)]
            outl['cdr3b'] = new_cdr3b

        if save_sorted_chainseqs:
            outl['sorted_chainseqs'] = sorted_chainseqs

        dfl.append(outl)

    targets = pd.DataFrame(dfl)
    return targets # same as starting targets except for chainseq column



def encode_target_for_rf_ab(
        pmhc_pose,
        va_seq,
        vb_seq,
        verbose=False,
        ):
    from rf_ab_chemical import aa2long, one_letter
    aa2int = {aa:i for i,aa in enumerate(one_letter)}
    cbs = pmhc_pose['chainbounds']
    #num_pmhc_chains = len(cbs)-1
    # assert len(cbs) in [3,4]
    # mhc_class = len(cbs) - 2
    # nres_mhc = cbs[-2]
    nres = cbs[-1]
    # nres_peptide = cbs[-1] - cbs[-2]

    #In [36]: info.keys()
    #Out[36]: dict_keys(['T', 'Hseq', 'Lseq', 'hotspots'])
    # based on xtal_3qiu encoding, Hseq is the alpha chain and Lseq is the beta chain
    info = {'Hseq':va_seq, 'Lseq':vb_seq, 'hotspots':[False]*nres}

    #In [26]: info['T'].keys()
    #Out[26]: dict_keys(['xyz', 'seq', 'pdb_idx', 'idx', 'cdr_bool', 'mask'])
    tinfo = {}
    tinfo['idx'] = list(range(nres))

    chains = []
    for chain,start,stop in zip('ABCDEFGHIJKLMNOPQRSTUVWXYZ', cbs[:-1], cbs[1:]):
        chains.extend([chain]*(stop-start))
    assert len(chains) == nres
    tinfo['pdb_idx'] = list(zip(chains, map(str, tinfo['idx'])))
    tinfo['cdr_bool'] = [False]*nres
    tinfo['seq'] = [aa2int[x] for x in pmhc_pose['sequence']]
    tinfo['xyz'] = []
    tinfo['mask'] = []
    for ii, (r,aa) in enumerate(zip(pmhc_pose['resids'], pmhc_pose['sequence'])):
        iaa = aa2int[aa]
        atom_names = aa2long[iaa]
        assert len(atom_names) == 27
        ii_xyz = [[np.nan, np.nan, np.nan] for _ in range(len(atom_names))]
        ii_mask = [False]*len(atom_names)
        for atom, v in pmhc_pose['coords'][r].items():
            if atom in atom_names:
                idx = atom_names.index(atom)
                for k in range(3):
                    ii_xyz[idx][k] = v[k]
                ii_mask[idx] = True
            else:
                if verbose:
                    print('unrecognized atom_name:', atom, aa)
        tinfo['xyz'].append(ii_xyz)
        tinfo['mask'].append(ii_mask)

    info['T'] = tinfo
    return info


def encode_target_for_rf_ab_old(
        pmhc_pose,
        va_seq,
        vb_seq,
        verbose=False,
        ):

    from rf_ab_chemical import aa2long, one_letter
    aa2int = {aa:i for i,aa in enumerate(one_letter)}
    cbs = pmhc_pose['chainbounds']
    assert len(cbs) in [3,4]
    mhc_class = len(cbs) - 2
    nres_mhc = cbs[-2]
    nres = cbs[-1]
    nres_peptide = cbs[-1] - cbs[-2]

    #In [36]: info.keys()
    #Out[36]: dict_keys(['T', 'Hseq', 'Lseq', 'hotspots'])
    # based on xtal_3qiu encoding, Hseq is the alpha chain and Lseq is the beta chain
    info = {'Hseq':va_seq, 'Lseq':vb_seq, 'hotspots':[False]*nres}

    #In [26]: info['T'].keys()
    #Out[26]: dict_keys(['xyz', 'seq', 'pdb_idx', 'idx', 'cdr_bool', 'mask'])
    tinfo = {}
    tinfo['idx'] = list(range(nres))
    if mhc_class==1:
        chains = ['A']*nres_mhc + ['B']*nres_peptide
    else:
        chains = ['A']*cbs[1] + ['B']*(cbs[2]-cbs[1]) + ['C']*nres_peptide
    tinfo['pdb_idx'] = list(zip(chains, map(str, tinfo['idx'])))
    tinfo['cdr_bool'] = [False]*nres
    tinfo['seq'] = [aa2int[x] for x in pmhc_pose['sequence']]
    tinfo['xyz'] = []
    tinfo['mask'] = []
    for ii, (r,aa) in enumerate(zip(pmhc_pose['resids'], pmhc_pose['sequence'])):
        iaa = aa2int[aa]
        atom_names = aa2long[iaa]
        assert len(atom_names) == 27
        ii_xyz = [[np.nan, np.nan, np.nan] for _ in range(len(atom_names))]
        ii_mask = [False]*len(atom_names)
        for atom, v in pmhc_pose['coords'][r].items():
            if atom in atom_names:
                idx = atom_names.index(atom)
                for k in range(3):
                    ii_xyz[idx][k] = v[k]
                ii_mask[idx] = True
            else:
                if verbose:
                    print('unrecognized atom_name:', atom, aa)
        tinfo['xyz'].append(ii_xyz)
        tinfo['mask'].append(ii_mask)

    info['T'] = tinfo
    return info




def run_rf_antibody_on_designs(
        targets,
        outprefix,
        # useful if mpnn made chainseq, pdbseq is old:
        allow_pdb_chainseq_mismatch_for_tcr=False,
        dry_run = False,
        delete_old_results = False,
        model_path = None,
        reverse_chains = False,
        deterministic = False, # match legacy behavior, may want to change?
        rfab_script = None, # location of rf antibody python script
):
    required_cols = 'targetid chainseq model_pdbfile'.split()
    for col in required_cols:
        assert col in targets.columns

    if model_path is None:
        model_path = design_paths.RFAB_CHK
    if rfab_script is None:
        rfab_script = design_paths.RFAB_SCRIPT

    assert targets.targetid.value_counts().max()==1 # unique

    assert exists(design_paths.RFAB_PYTHON)
    assert exists(rfab_script)
    assert exists(model_path)


    all_info = {}
    for l in targets.itertuples():
        pose = td2.pdblite.pose_from_pdb(l.model_pdbfile)
        #assert len(pose['chains']) == 1 # not if coming from rf_ab_diff pipeline?
        cs = l.chainseq.split('/')
        chainbounds = [0] + list(it.accumulate(len(x) for x in cs))
        if not allow_pdb_chainseq_mismatch_for_tcr:
            assert pose['sequence'] == ''.join(cs)
        else:
            nres_pmhc = chainbounds[-3]
            assert pose['sequence'][:nres_pmhc] == ''.join(cs)[:nres_pmhc]

        pose = td2.pdblite.set_chainbounds_and_renumber(pose, chainbounds)
        nchains = len(pose['chains'])
        pmhc_pose = td2.pdblite.delete_chains(pose, [nchains-2, nchains-1])

        va_seq, vb_seq = cs[-2:]
        if reverse_chains or ('reverse_dock' in targets.columns and l.reverse_dock):
            # actually based on encode_target_for_rf_ab it looks like the
            # default is VA --> VH and VB --> VL
            print('run_rf_antibody_on_designs:: reversing TCR chains:',
                  'TCRB passed as VH and TCRA passed as VL')
            vb_seq, va_seq = va_seq, vb_seq

        info = encode_target_for_rf_ab(pmhc_pose, va_seq, vb_seq)
        all_info[l.targetid] = info


    outdir = outprefix+'_rfab/'
    if not exists(outdir):
        mkdir(outdir)

    outfile = f'{outdir}rfab_targets.json'
    with open(outfile, 'w') as f:
        f.write(json.dumps(all_info)+'\n')
    print('made:', outfile)

    if delete_old_results:
        for targetid in targets.targetid:
            pdbfile = f'{outdir}{targetid}_best.pdb'
            if exists(pdbfile):
                print('WARNING removing old rf_antibody pdbfile:', pdbfile)
                remove(pdbfile)
            resfile = f'{outdir}{targetid}.npz' # results
            if exists(resfile):
                print('WARNING removing old rf_antibody resfile:', resfile)
                remove(resfile)


    # Updated RFantibody parameters to most experimentally validated parameters
    # as of Oct 2023
    xargs = ' --deterministic ' if deterministic else ''
    cmd = (f'{design_paths.RFAB_PYTHON} -u {rfab_script} {xargs} '
           f' --model_path {model_path} '
           f' --mask_ab_sidechains --mask_target_sidechains '
           f' --hotspot_prop 0 --num_recycles 10 --no_crop --output_path {outdir} '
           f' --sequence_json {outfile} > {outprefix}.log 2> {outprefix}.err')
    print(cmd)
    if not dry_run:
        system(cmd)


    dfl = []
    for _, l in targets.iterrows():
        pdbfile = f'{outdir}{l.targetid}_best.pdb'
        resfile = f'{outdir}{l.targetid}.npz' # results
        assert exists(pdbfile) and exists(resfile), \
            f'rf_antibody failed for target: {l.targetid}'

        res = np.load(resfile)

        pose = td2.pdblite.pose_from_pdb(pdbfile)
        cbs = [0] + list(it.accumulate(len(x) for x in l.chainseq.split('/')))
        lseq = l.chainseq.replace('/','')

        if reverse_chains or ('reverse_dock' in targets.columns and l.reverse_dock):
            nres_pmhc, _, nres = cbs[-3:]
            vaseq, vbseq = l.chainseq.split('/')[-2:]
            assert pose['sequence'] == lseq[:nres_pmhc] + vbseq + vaseq
            stop = nres_pmhc + len(vbseq)
            new_resids = (pose['resids'][:nres_pmhc]+
                          pose['resids'][stop:]+
                          pose['resids'][nres_pmhc:stop])
            pose = {'resids':new_resids, 'coords':pose['coords'], 'sequence':lseq}
            pose = td2.pdblite.update_derived_data(pose)

        assert pose['sequence'] == lseq

        pose = td2.pdblite.set_chainbounds_and_renumber(pose, cbs)
        outl = l.copy()
        outl['old_model_pdbfile'] = l.model_pdbfile
        outl['model_pdbfile'] = pdbfile
        if reverse_chains or ('reverse_dock' in targets.columns and l.reverse_dock):
            print('overwrite old pdbfile:', pdbfile)
            td2.pdblite.dump_pdb(pose, pdbfile)

        outl['rfab_pbind'] = res['p_bind'][0]
        outl['rfab_pmhc_tcr_pae'] = res['pae_interaction']

        dginfo = design_stats.compute_docking_geometry_info(l, pose=pose)
        if dginfo is not None:
            for k,v in dginfo.items():
                outl[k] = v

        dfl.append(outl)

    results = pd.DataFrame(dfl)
    return results

def setup_rf_diff_tcr_template(pdbid, nterm_seq_stem=3, cterm_seq_stem=2):
    ''' returns:

    tcr_template_pdbfile, design_loops

    design_loops looks like ['H1:5', 'H2:6', 'H3:15', 'L1:4', 'L2:7', 'L3:18']

    note that H is TCR alpha chain and L is TCR beta chain !!

    '''
    outfile = (f'{td2.util.path_to_db}/rf_diff_templates/'
               f'{pdbid}_tcr_n{nterm_seq_stem}_c{cterm_seq_stem}.pdb')

    all_ternary_info = pd.concat([td2.sequtil.ternary_info,
                                  td2.sequtil.new_ternary_info])
    row = all_ternary_info.loc[pdbid]
    print('setup_rf_diff_tcr_template:', pdbid, outfile)

    pdbfile = str(td2.util.path_to_db / row.pdbfile)
    pose = td2.pdblite.pose_from_pdb(pdbfile)

    tdifile = pdbfile+'.tcrdock_info.json'
    with open(tdifile, 'r') as f:
        tdinfo = td2.tcrdock_info.TCRdockInfo().from_string(f.read())

    nres_pmhc = pose['chainbounds'][2]
    tdinfo.delete_residue_range(0, nres_pmhc)
    pose = td2.pdblite.delete_chains(pose, [0,1])
    _, nres_tcra, nres = pose['chainbounds']

    resids = ([('H', f'{i:4d} ') for i in range(1, nres_tcra+1)]+
              [('L', f'{i:4d} ') for i in range(nres_tcra+1, nres+1)])
    coords = {newr: pose['coords'][oldr]
              for oldr, newr in zip(pose['resids'], resids)}
    pose['resids'] = resids
    pose['coords'] = coords
    pose = td2.pdblite.update_derived_data(pose)

    if not exists(outfile):
        td2.pdblite.dump_pdb(pose, outfile)
        print('made:', outfile)
        out = open(outfile, 'a')
    else:
        out = None

    design_loops = []
    for ii, loop in enumerate(tdinfo.tcr_cdrs):
        if ii in [2,6]:
            continue
        hl = 'H' if ii<4 else 'L'
        num = ii%4 + 1
        start, stop = loop
        if num == 4:
            num = 3
            start += nterm_seq_stem
            stop -= cterm_seq_stem

        if out is not None:
            for pos in range(start, stop+1):
                out.write(f'REMARK PDBinfo-LABEL: {pos+1:4d} {hl}{num}\n')
        print('cdr', hl, num, pose['sequence'][start:stop+1])

        looplen = stop-start+1
        design_loops.append(f'{hl}{num}:{looplen}')

    if out is not None:
        out.close()

    return outfile, design_loops


def setup_rf_diff_pmhc_template(pdbid, n_hotspot=3):
    ''' returns

    pdbfile, hotspot_string
    '''

    outfile = f'{td2.util.path_to_db}/rf_diff_templates/{pdbid}_pmhc_hs{n_hotspot}.pdb'

    all_ternary_info = pd.concat([td2.sequtil.ternary_info,
                                  td2.sequtil.new_ternary_info])
    all_pmhc_info = pd.concat([td2.sequtil.pmhc_info, # could add new_ternary_info
                               td2.sequtil.new_pmhc_info]) # not necessary
    if pdbid in all_ternary_info.index:
        row = all_ternary_info.loc[pdbid]
    else:
        row = all_pmhc_info.loc[pdbid]

    cbs = [0]+list(it.accumulate(len(x) for x in row.chainseq.split('/')))
    #assert len(cbs) == row.mhc_class + 4 # == num_chains + 1
    nres_mhc = cbs[row.mhc_class]

    # 1-indexed numbers
    # start at the fourth peptide position (skip the first 3)
    hotspot_string = '[' + ','.join(f'T{nres_mhc+4+i}' for i in range(n_hotspot)) + ']'

    if not exists(outfile):
        # make target pdbfile
        pdbfile = td2.util.path_to_db / row.pdbfile
        pose = td2.pdblite.pose_from_pdb(pdbfile)
        nchains = len(pose['chains'])
        if nchains > row.mhc_class+1:
            assert nchains==row.mhc_class+3
            pose = td2.pdblite.delete_chains(pose, range(row.mhc_class+1, nchains))
        nres = len(pose['sequence'])
        resids = [('T', f'{i:4d} ') for i in range(1, nres+1)]
        coords = {newr: pose['coords'][oldr]
                  for oldr, newr in zip(pose['resids'], resids)}
        pose['resids'] = resids
        pose['coords'] = coords
        pose = td2.pdblite.update_derived_data(pose)

        td2.pdblite.dump_pdb(pose, outfile)
        print('made:', outfile)

    return outfile, hotspot_string


def setup_extra_pmhc_templates(pmhcs, outfile_prefix):
    ''' This is for adding additional pMHC templates into the AF2 modeling
    See dock_design.py for an example
    '''
    import tcrdock.setup
    required_cols = 'organism mhc_class pdbfile pdbid'.split()
    dfl = []

    seen = set()
    for _, l in pmhcs.iterrows():
        if l.pdbfile in seen:
            continue
        seen.add(l.pdbfile)

        pose, tdinfo = td2.setup.load_and_setup_tcrdock_pose(
            l.pdbfile, l.organism, l.mhc_class, pmhc_only=True
        )

        new_pdbfile = f'{outfile_prefix}{l.pdbid}_orient.pdb'
        td2.pdblite.dump_pdb(pose, new_pdbfile)
        print('made:', new_pdbfile)
        tdifile = new_pdbfile+'.tcrdock_info.json'
        with open(tdifile, 'w') as f:
            f.write(tdinfo.to_string())
            print('made:', tdifile)

        mhc_seq, tmp = pose['chainseq'].split('/')
        assert tmp == tdinfo.pep_seq

        mhc_alignseq = td2.sequtil.get_mhc_class_1_mhc_alignseq_from_chainseq(
            tdinfo.mhc_allele, mhc_seq, info=l.pdbfile)

        breaks, totals = td2.pdblite.find_chainbreaks(
            pose, return_total_chainbreak_by_chain=True)

        mhc_total_chainbreak = sum(totals[:l.mhc_class])
        pep_chainbreak = totals[l.mhc_class]
        assert pep_chainbreak < 1e-2

        mhc = ':'.join(tdinfo.mhc_allele.split(':')[:2]) # trim extra ":01:01" junk
        outl = dict(
            organism=l.organism,
            mhc_class=l.mhc_class,
            mhc_allele=mhc,
            pep_seq=tdinfo.pep_seq,
            pdbfile = new_pdbfile,
            chainseq = pose['chainseq'],
            mhc_alignseq=mhc_alignseq,
            mhc_total_chainbreak = mhc_total_chainbreak,
            pdbid=l.pdbid,
        )
        dfl.append(outl)

    extra_pmhc_templates = pd.DataFrame(dfl).set_index('pdbid', drop=False)
    return extra_pmhc_templates


## these next two functions are for preprocessing inputs to RFantibody, which shows
# a surprising sensitivity to extra residues at the termini

def get_mhc_class_1_trims(seq, mhc_allele):
    ''' returns ntrim, ctrim
    '''
    fullseq = td2.sequtil.get_mhc_class_1_alseq(mhc_allele).replace(
        td2.sequtil.ALL_GENES_GAP_CHAR, '')

    al = td2.sequtil.blosum_align(seq, fullseq)

    shift_counts = Counter(y-x for x,y in al.items())
    if len(shift_counts)>1:
        print('get_mhc_class_1_trims:: gapped align??', shift_counts)
    shift = shift_counts.most_common()[0][0]
    ntrim = 0-shift
    # what maps to 0? 0-shift
    # what maps to len(fullseq)-1 ? len(fullseq)-1 - shift
    #
    ctrim = (len(seq)-1) - (len(fullseq)-1-shift)
    return ntrim, ctrim


def get_tcr_trims(seq, organism, ab, vgene, jgene):
    ''' returns ntrim, ctrim
    '''
    vseq = td2.sequtil.get_v_seq_up_to_cys(organism, vgene)
    jseq = td2.sequtil.get_j_seq_after_cdr3(organism, jgene)

    al = td2.sequtil.blosum_align(seq, vseq)
    a,b = min(al.items())
    shift = b-a
    ntrim = 0-shift

    al = td2.sequtil.blosum_align(seq, jseq)
    a,b = max(al.items())
    shift = b-a
    ctrim = (len(seq)-1) - (len(jseq)-1-shift)
    return ntrim, ctrim


def make_templates_for_alphafold_simple(
        organism,
        pmhc_pdbid,
        framework_pdbid,
        mhc_seq,
        tcra_seq,
        tcrb_seq,
        outfile_prefix,
        verbose=True,
):
    ''' return DataFrame that can be saved as alignfile

    assumes we keep the peptide from pmhc_pdbid

    '''
    from tcrdock.sequtil import (
        ternary_info, new_ternary_info, pmhc_info, new_pmhc_info,
    )
    from tcrdock.util import path_to_db
    from tcrdock.tcrdock_info import TCRdockInfo
    from numpy.linalg import norm

    assert organism in ['human','mouse'] # organism for mhc

    my_ternary_info = pd.concat([ternary_info, new_ternary_info])
    badmask = new_ternary_info.pdbid.isin(set(pmhc_info.pdbid))
    my_pmhc_info = pd.concat([pmhc_info, new_ternary_info[~badmask], new_pmhc_info])

    pmhc_row = my_pmhc_info.loc[pmhc_pdbid]
    framework_row = my_ternary_info.loc[framework_pdbid]

    assert pmhc_row.mhc_class == 1 # for the time being
    peptide = pmhc_row.pep_seq

    pmhc_pdbfile = str(path_to_db / pmhc_row.pdbfile)
    pmhc_pose = td2.pdblite.pose_from_pdb(pmhc_pdbfile)
    with open(pmhc_pdbfile+'.tcrdock_info.json','r') as f:
        pmhc_tdinfo = TCRdockInfo().from_string(f.read())
    nch = len(pmhc_pose['chains'])
    if nch > pmhc_row.mhc_class+1:
        pmhc_pose = td2.pdblite.delete_chains(
            pmhc_pose, range(pmhc_row.mhc_class+1, nch))

    framework_pdbfile = str(path_to_db / framework_row.pdbfile)
    framework_pose = td2.pdblite.pose_from_pdb(framework_pdbfile)
    with open(framework_pdbfile+'.tcrdock_info.json','r') as f:
        framework_tdinfo = TCRdockInfo().from_string(f.read())

    nch = len(framework_pose['chains'])
    ndel = framework_pose['chainbounds'][-3]

    framework_pose = td2.pdblite.delete_chains(framework_pose, range(nch-2))
    framework_tdinfo.delete_residue_range(0, ndel)
    framework_tdinfo.mhc_core = None # no longer makes sense


    tmp_pose = copy.deepcopy(pmhc_pose)
    tmp_pose = td2.pdblite.append_chains(tmp_pose, framework_pose, [0,1])
    tmp_pose = td2.pdblite.set_chainbounds_and_renumber(
        tmp_pose, list(tmp_pose['chainbounds']))


    trg_chainseq = mhc_seq + '/' + peptide + '/' + tcra_seq + '/' + tcrb_seq

    trg_fullseq = trg_chainseq.replace('/','')
    tmp_fullseq = tmp_pose['sequence']


    # setup the alignment
    #nres_pmhc = len(pmhc_pose['sequence'])
    #align = {i:i for i in range(nres_pmhc)}
    mhc_seq_tmp = pmhc_pose['chainseq'].split('/')[0] # only makes sense for cls 1 now
    nres_pmhc_trg = len(mhc_seq)+len(peptide)
    nres_pmhc_tmp = len(mhc_seq_tmp)+len(peptide)
    assert nres_pmhc_tmp == len(pmhc_pose['sequence'])

    # align mhc
    align = td2.sequtil.blosum_align(mhc_seq, mhc_seq_tmp, verbose=True)

    # align peptide
    align.update({len(mhc_seq)+i:len(mhc_seq_tmp)+i
                  for i in range(len(peptide))})

    framework_tdinfo.renumber({i:i+nres_pmhc_tmp
                               for i in range(len(framework_pose['sequence']))})

    offset_trg, offset_fw = nres_pmhc_trg, nres_pmhc_tmp
    for ab, seq, fwseq, cdrs in zip('AB', [tcra_seq, tcrb_seq],
                                    framework_pose['chainseq'].split('/'),
                                    [framework_tdinfo.tcr_cdrs[:4],
                                     framework_tdinfo.tcr_cdrs[4:]]):
        print('TCR'+ab)
        # new approach, try to align the framework regions individually
        for ic in range(len(cdrs)+1):
            if ic==0:
                start = 0
            else:
                start = cdrs[ic-1][1]+1-offset_fw
            if ic==len(cdrs):
                stop = len(fwseq)
            else:
                stop = cdrs[ic][0]-offset_fw

            al = td2.sequtil.blosum_align(seq, fwseq[start:stop], verbose=True,
                                          gap_open=-100)
            counts = Counter(y-x for x,y in al.items())
            #print(ic, start, stop, counts.most_common())
            assert len(fwseq[start:stop]) == stop-start
            shift = counts.most_common()[0][0]
            for ii in range(stop-start): ## ii is the index into fwseq[start:stop]
                if not (0 <= ii-shift < len(seq)):
                    continue
                pos1 = ii - shift + offset_trg
                pos2 = ii + start + offset_fw
                #print(pos1, trg_fullseq[pos1], pos2, tmp_fullseq[pos2])
                assert 0 <= pos1 < len(trg_fullseq)
                assert 0 <= pos2 < len(tmp_fullseq)
                align[pos1] = pos2

        offset_trg += len(seq)
        offset_fw += len(fwseq)

        #adjust the alignment around the cdrs
        rev_align = {j:i for i,j in align.items()}
        for start, stop in cdrs:
            c, d = start-2, stop+2 # bound the loop
            a, b = rev_align[c], rev_align[d] # could fail, hopefully not
            if b-a != d-c:
                # looplen mismatch, adjust gap position
                shortlen = min(d-c+1, b-a+1)
                gappos = shortlen//2
                for i in range(a,b+1):
                    if i in align:
                        del align[i]
                for i in range(gappos):
                    align[a+i] = c+i
                for i in range(shortlen-gappos):
                    align[b-i] = d-i
            else: # should be no gap in there...
                for ii in range(b-a+1):
                    align[a+ii] = c+ii


    # template tdinfo
    tmp_tdinfo = copy.deepcopy(framework_tdinfo)
    tmp_tdinfo.mhc_class = pmhc_tdinfo.mhc_class
    tmp_tdinfo.mhc_allele = pmhc_tdinfo.mhc_allele
    tmp_tdinfo.mhc_core = pmhc_tdinfo.mhc_core[:]
    tmp_tdinfo.pep_seq = pmhc_tdinfo.pep_seq

    assert tmp_pose['sequence'][tmp_tdinfo.tcr_cdrs[3][0]]=='C'
    assert tmp_pose['sequence'][tmp_tdinfo.tcr_cdrs[7][0]]=='C'
    assert tmp_pose['sequence'][tmp_tdinfo.tcr_core[ 1]]=='C'
    assert tmp_pose['sequence'][tmp_tdinfo.tcr_core[12]]=='C'
    assert tmp_pose['sequence'][tmp_tdinfo.tcr_core[14]]=='C'
    assert tmp_pose['sequence'][tmp_tdinfo.tcr_core[25]]=='C'

    # set canonical MHC orientation (at origin)
    tmp_pose = td2.mhc_util.orient_pmhc_pose(tmp_pose, tdinfo=tmp_tdinfo)

    trg_tdinfo = copy.deepcopy(tmp_tdinfo)
    trg_tdinfo.renumber({j:i for i,j in align.items()})


    cys_posl = [trg_tdinfo.tcr_core[1], trg_tdinfo.tcr_core[12],
                trg_tdinfo.tcr_core[14], trg_tdinfo.tcr_core[25],
                trg_tdinfo.tcr_cdrs[3][0], trg_tdinfo.tcr_cdrs[7][0]]
    cys_poslstring = ''.join(trg_fullseq[x] for x in cys_posl)
    assert cys_poslstring == 'CCCCCC', \
        f'bad cysteines? {abid} {cdr3a} {cdr3b} {cys_poslstring}'

    def show_alignment(al,seq1,seq2):
        if False and verbose:
            for i,j in sorted(al.items()):
                a,b = seq1[i], seq2[j]
                star = '*' if a==b else ' '
                lgap = '+' if i+1 not in al else ' '
                rgap = '+' if j+1 not in al.values() else ' '
                print(f'{i:4d} {j:4d} {a}{lgap}{star}{rgap}{b}')
            idents = sum(seq1[i] == seq2[j] for i,j in al.items())/len(seq1)
            print(f'idents: {idents:6.3f}')


    show_alignment(align, trg_fullseq, tmp_fullseq)
    assert Counter(align.values()).most_common()[0][1] == 1#no dups

    rep_dgeoms = td2.docking_geometry.load_opt_dgeoms(pmhc_row.mhc_class)
    assert len(rep_dgeoms) == 4


    # now make the template pdbs

    dfl = []
    for itmp, dgeom in enumerate(rep_dgeoms):
        mov_pose = copy.deepcopy(tmp_pose)

        old_tcr_stub = td2.tcr_util.get_tcr_stub(mov_pose, tmp_tdinfo)
        new_tcr_stub = td2.docking_geometry.stub_from_docking_geometry(
            dgeom)
        # R @ old_tcr_stub['axes'].T = new_tcr_stub['axes'].T
        R = new_tcr_stub['axes'].T @ old_tcr_stub['axes']
        # R @ old_tcr_stub['origin'] + v = new_tcr_stub['origin']
        v = new_tcr_stub['origin'] - R@old_tcr_stub['origin']
        mov_pose = td2.pdblite.apply_transform_Rx_plus_v(mov_pose, R, v)

        # rotate/translate the TCR in tmp_pose
        for i in range(nres_pmhc_tmp, len(tmp_pose['sequence'])):
            res = tmp_pose['resids'][i]
            for a, v in mov_pose['coords'][res].items():
                tmp_pose['coords'][res][a] = np.array(v)
        tmp_pose = td2.pdblite.update_derived_data(tmp_pose)

        redo_tcr_stub = td2.tcr_util.get_tcr_stub(tmp_pose, tmp_tdinfo)
        redo_dgeom = td2.docking_geometry.get_tcr_pmhc_docking_geometry(
            tmp_pose, tmp_tdinfo)
        v_dev = norm(redo_tcr_stub['origin']-new_tcr_stub['origin'])
        M_dev = norm(new_tcr_stub['axes'] @ redo_tcr_stub['axes'].T - np.eye(3))
        if max(v_dev, M_dev)>5e-2:
            print('ERROR devs:', v_dev, M_dev)
        assert v_dev<5e-2
        assert M_dev<5e-2

        # could also recompute the dgeom
        dgeom_dev = td2.docking_geometry.compute_docking_geometries_distance_matrix(
            [dgeom], [redo_dgeom])[0,0]
        assert dgeom_dev<1e-1, f'ERROR big dgeom_dev: {dgeom_dev}'


        identities = sum(trg_fullseq[i]==tmp_fullseq[j] for i,j in align.items())
        overall_idents = identities/len(trg_fullseq)

        outpdbfile = f'{outfile_prefix}_{itmp}.pdb'
        td2.pdblite.dump_pdb(tmp_pose, outpdbfile)
        #print('made:', outpdbfile)

        alignstring = ';'.join(f'{i}:{j}' for i,j in align.items())

        outl = OrderedDict(
            template_no=itmp,
            target_chainseq=trg_chainseq,
            overall_idents=overall_idents,
            template_pdbfile=outpdbfile,
            target_to_template_alignstring=alignstring,
            identities=identities,
            target_len=len(trg_fullseq),
            template_len=len(tmp_fullseq),
            target_tdinfo=trg_tdinfo.to_string(),
        )
        dfl.append(outl)
    return pd.DataFrame(dfl)



def setup_for_alphafold_simple(
        tcr_db,
        outdir,
        **kwargs,
):
    ''' Borrowed from tcrdock/sequtil.py, modified
    '''
    assert outdir.endswith('/')
    required_cols = 'organism pmhc_pdbid framework_pdbid tcra_seq tcrb_seq'.split()
    for col in required_cols:
        assert col in tcr_db.columns, f'Need {col} column in tcr_db'

    makedirs(outdir, exist_ok=True)

    tcr_db_outfile = outdir+'tcr_db.tsv'
    tcr_db.to_csv(tcr_db_outfile, sep='\t', index=False)

    targets_dfl = []
    for index, targetl in tcr_db.reset_index().iterrows():
        targetid = f'T{index:05d}_{targetl.pmhc_pdbid}_{targetl.framework_pdbid}'
        print('START', index, tcr_db.shape[0], targetid)
        outfile_prefix = f'{outdir}{targetid}'

        info = make_templates_for_alphafold_simple(
            targetl.organism, targetl.pmhc_pdbid, targetl.framework_pdbid,
            targetl.mhc_seq, targetl.tcra_seq, targetl.tcrb_seq, outfile_prefix,
        )

        assert info.shape[0] == 4#num templates
        trg_cbseq = set(info.target_chainseq).pop()
        alignfile = f'{outdir}{targetid}_alignments.tsv'
        info.to_csv(alignfile, sep='\t', index=False)
        outl = targetl.copy()
        outl['targetid'] = targetid
        outl['chainseq'] = trg_cbseq
        outl['alignfile'] = alignfile
        outl['target_tdinfo'] = info.target_tdinfo.iloc[0]
        targets_dfl.append(outl)

    outfile = outdir+'targets.tsv'
    targets = pd.DataFrame(targets_dfl)
    targets.to_csv(outfile, sep='\t', index=False)
    print('made:', outfile)
    return targets



def run_rosetta_relax(
        targets,
        outprefix,
        ex_flags = False,
        relax_rescored_model = False,
        norelax = False,
):
    required_cols = 'chainseq model_pdbfile'.split()

    # need these in order to be able to define the flexible loops in the design
    need_one_of_cols = (
        'template_0_target_to_template_alignstring designable_positions').split()

    for col in required_cols:
        assert col in targets.columns, f'run_rosetta_relax: Need {col} in targets'

    assert any(x in targets.columns for x in need_one_of_cols),\
        f'run_rosetta_relax: Need one of {" ".join(need_one_of_cols)}'


    PY = design_paths.PYROSETTA_PYTHON
    EXE = design_paths.path_to_design_scripts / 'relax_af2_designs.py'
    assert exists(PY) and exists(EXE)

    xargs = ' --mute '
    if ex_flags:
        xargs += ' --ex1 --ex2 '
    if norelax:
        xargs += ' --norelax '


    # the new columns we will be adding
    new_cols = ('relax_bound_score '
                'relax_peptide_score relax_peptide_score_len_norm '
                'relax_loop_score relax_loop_score_len_norm '
                'relax_peptide_loop_intxn relax_peptide_loop_intxn_len_norm '
                'relaxed_peptide_rmsd relaxed_loop_rmsd '
                'relax_binding_energy_frozen relax_loop_seq relax_time '
                'total_loop_sap mean_loop_sap total_peptide_sap mean_peptide_sap '
                'total_loop_saps mean_loop_saps '
                'has_loop_disulfide has_pep_disulfide').split()
    dropcols = [x for x in new_cols if x in targets.columns]
    if dropcols:
        print('run_rosetta_relax:: dropping these columns from targets', dropcols)
        targets.drop(columns=dropcols, inplace=True)

    targets_file = outprefix+'_targets.tsv'
    relax_targets = targets.copy()
    if relax_rescored_model:
        print('using rescored models for relax inputs')
        print(relax_targets.rescore_model_pdbfile.head())
        print('instead of')
        print(relax_targets.model_pdbfile.head())
        relax_targets['model_pdbfile'] = relax_targets.rescore_model_pdbfile
    relax_targets.to_csv(targets_file, sep='\t', index=False)

    cmd = (f'{PY} {EXE} {xargs} --targets {targets_file} '
           f' --outfile_prefix {outprefix} > {outprefix}.log '
           f' 2> {outprefix}.err')
    print(cmd)
    system(cmd)

    resultsfile = outprefix+'_relax_af2_designs.tsv'
    assert exists(resultsfile), 'relax_af2_designs failed! '+outprefix
    original_cols = list(targets.columns)
    results = pd.read_table(resultsfile).set_index('targetid', drop=False)
    assert results.shape[0] == targets.shape[0], 'relax_af2_designs partial!'

    name_map = dict(
        bound_score= 'relax_bound_score',
        pep_score= 'relax_peptide_score',
        loop_score= 'relax_loop_score',
        pep_loop_intxn= 'relax_peptide_loop_intxn',
        binding_energy_frozen= 'relax_binding_energy_frozen',
        seq_peptide= 'relax_peptide',
        seq_loop= 'relax_loop_seq',
    )
    oldcols = [x for x in name_map.values() if x in results.columns]
    if oldcols:
        results.drop(columns=oldcols, inplace=True)

    results.rename(columns=name_map, inplace=True)

    # add length-normalized versions of the relax scores
    results['peplen'] = results.relax_peptide.str.len()
    results['looplen'] = results.relax_loop_seq.str.len()
    results['relax_peptide_score_len_norm'] = (
        results.relax_peptide_score / results.peplen)
    results['relax_loop_score_len_norm'] = (
        results.relax_loop_score / results.looplen)
    results['relax_peptide_loop_intxn_len_norm'] = (
        results.relax_peptide_loop_intxn / (results.peplen*results.looplen))

    targets = targets.join(results, on='targetid', rsuffix='_r')

    assert not any(x in new_cols for x in original_cols) # no overlap

    return targets[original_cols+new_cols]



def run_sasas_and_contacts(
        targets,
        outprefix,
        verbose=False,
):
    required_cols = 'chainseq model_pdbfile'.split()


    for col in required_cols:
        assert col in targets.columns, f'run_rosetta_relax: Need {col} in targets'

    PY = design_paths.PYROSETTA_PYTHON
    EXE = design_paths.path_to_design_scripts / 'compute_tcr_sasas_and_contacts.py'
    assert exists(PY) and exists(EXE)

    xargs = ' --mute ' if not verbose else ' '

    # the new columns we will be adding
    new_cols = [
        'mhc_contacts_7', 'pep_contacts_7',
        'mhc_atom_contacts_4.5', 'pep_atom_contacts_4.5', 'pep_bb_hbonds',
        'pep_sasa_unbound_0.5', 'pep_sasa_bound_0.5', 'pep_bsasa_0.5',
        'pep_bsasa_frac_0.5',
        'pep_sasa_unbound_1.0', 'pep_sasa_bound_1.0', 'pep_bsasa_1.0',
        'pep_bsasa_frac_1.0',
        'mhc_bsasa_1.4',
        'pep_sasa_unbound_1.4', 'pep_sasa_bound_1.4', 'pep_bsasa_1.4',
        'pep_bsasa_frac_1.4',
    ]

    dropcols = [x for x in new_cols if x in targets.columns]
    if dropcols:
        print('run_sasas_and_contacts:: dropping these columns from targets', dropcols)
        targets.drop(columns=dropcols, inplace=True)

    targets_file = outprefix+'_targets.tsv'
    targets.to_csv(targets_file, sep='\t', index=False)

    resultsfile = outprefix+'get_contacts.tsv'
    cmd = (f'{PY} {EXE} {xargs} --targets {targets_file} '
           f' --outfile {resultsfile} > {outprefix}.log '
           f' 2> {outprefix}.err')
    print(cmd)
    system(cmd)

    assert exists(resultsfile), 'compute_tcr_sasas_and_contacts.py failed! '+outprefix
    original_cols = list(targets.columns)
    results = pd.read_table(resultsfile)
    assert results.shape[0] == targets.shape[0], \
        'compute_tcr_sasas_and_contacts partial!'

    good_cols = [x for x in results.columns if x in original_cols or x in new_cols]
    missed_cols = [x for x in new_cols if x not in results.columns]
    if missed_cols:
        print('WARNING: compute_tcr_sasas_and_contacts missed expected cols:',
              missed_cols)

    return results[good_cols].copy()


def randomly_orient_target_for_generic_dock_design(
        pose,
        hotspot,
        num_nbrs=30,
        x_shift=15.,
):
    # get the closest num_nbrs residues
    coords = pose['ca_coords']
    c = coords[hotspot]
    D2 = ((coords - c[None,:])**2).sum(axis=-1)
    nbrs = np.argsort(D2)[1:num_nbrs+1]
    #print('nbr_dists:', [np.sqrt(D2[x]) for x in nbrs])

    com = coords[nbrs].mean(axis=0)
    x_axis = (c - com)/np.linalg.norm(c-com)
    center = c - x_shift*x_axis

    y_axis = td2.geom_util.random_unit_vector()
    z_axis = np.cross(x_axis, y_axis)
    z_axis /= np.linalg.norm(z_axis)
    y_axis = np.cross(z_axis, x_axis)

    R = np.stack([x_axis, y_axis, z_axis])

    # x --> R*x + v
    # want to map center to 0,0,0
    v = -R@center

    pose = td2.pdblite.apply_transform_Rx_plus_v(pose, R, v)
    return pose


def show_hostname():
    import os
    import sys
    import datetime
    hostname = os.popen('hostname').readlines()[0].strip()
    now = datetime.datetime.now()
    msg = f'wrapper_tools.py:: show_hostname: hostname= {hostname} now= {now}'
    print(msg)
    sys.stderr.write(msg+'\n')

    
def run_alphafold3_on_tcr_targets(
        targets,
        outdir,
        interchain_templates,
        num_seeds = None, # None means just use the seeds in the input jsonfiles
):
    ''' Runs alphafold on all the JSON files in jsondir
    collects the results and returns results dataframe (also saves a TSV)

    targets must have: targetid chainseq af3_input_jsonfile

    AND info to get tdinfo, ie 'target_tdinfo' column or mhc/pep/va/etc

    all of the af3_input_jsonfiles must be in the same dir + be the only JSON files
      in that folder

    '''
    assert type(interchain_templates) is bool
    EXE = '/home/pbradley/gitrepos/alphafold3/run_af3_from_jsondir.sh'
    assert outdir.startswith('/') and outdir.endswith('/')

    required_cols = ('targetid chainseq af3_input_jsonfile'.split())
    if 'target_tdinfo' not in targets.columns:
        # need to be able to compute tdinfo
        required_cols.extend(
            'organism mhc_class mhc peptide va ja cdr3a vb jb cdr3b'.split())
    assert all(x in targets.columns for x in required_cols),\
        f'run_alphafold3_on_tcr_targets need these columns: {" ".join(required_cols)}'

    lens = (targets.chainseq.str.len() - targets.chainseq.str.count('/'))
    minlen, maxlen = lens.min(), lens.max()
    print(f'run_alphafold3_on_tcr_targets:: minlen= {minlen} maxlen= {maxlen}')
    # check about the jsonfiles: all in same dir + they are the only json files in there
    assert targets.targetid.value_counts().max() == 1
    assert targets.af3_input_jsonfile.map(exists).all()
    input_dir = set(targets.af3_input_jsonfile.map(dirname))
    assert len(input_dir) == 1
    input_dir = input_dir.pop() + '/'
    
    jsonfiles = glob(input_dir+'*.json')
    assert len(jsonfiles) == targets.shape[0]

    makedirs(outdir, exist_ok=True)
    cmd = f'{EXE} {input_dir} {outdir}'
    af3_xargs = ''
    if interchain_templates:
        af3_xargs += ' --interchain_templates '
    if num_seeds is not None:
        af3_xargs += f' --make_new_seeds {num_seeds} '
    if minlen > 0.9*maxlen:
        af3_xargs += f' --buckets {maxlen+1} '
        print(f'run_alphafold3_on_tcr_targets:: use buckets: {maxlen+1}')
        
    if af3_xargs:
        cmd += f' "{af3_xargs}" '
    cmd += f' > {outdir}run_alphafold3.log 2>&1'
    print(cmd)
    system(cmd)

    # now get the results
    dfl = []
    for _,row in targets.iterrows():
        name = td2.af3_util.sanitised_name(row.targetid) # just in case
        ciffile = f'{outdir}{name}/{name}_model.cif'
        conffile = f'{outdir}{name}/{name}_summary_confidences.json'
        if not exists(ciffile) and exists(conffile):
            print('run_af3 failed!', outdir, row.targetid, name)
            exit()
        pose = td2.pdblite.pose_from_cif(ciffile)
        with open(conffile) as f:
            res = json.load(f)
        assert pose['chainseq'] == row.chainseq,\
            f'chainseq mismatch: {name} {ciffile} {pose["chainseq"]} {row.chainseq}'
        tdinfo = design_stats.get_row_tdinfo(row, trust_tcr_positions=True)

        pose = td2.pdblite.renumber(pose)
        if tdinfo.mhc_core:
            pose = td2.mhc_util.orient_pmhc_pose(pose, tdinfo=tdinfo)

        pdbfile = ciffile[:-4]+'_orient.pdb'
        td2.pdblite.dump_pdb(pose, pdbfile)


        outl = row.copy()
        if 'target_tdinfo' not in targets.columns:
            outl['target_tdinfo'] = tdinfo.to_string()
        outl['af3_ciffile'] = ciffile
        outl['af3_conffile'] = conffile
        outl['model_pdbfile'] = pdbfile
        outl['iptm'] = res['iptm']
        outl['ranking_score'] = res['ranking_score']

        # should also add peptide, cdr avg plddts

        dfl.append(outl)
        
    results = pd.DataFrame(dfl)
    results.to_csv(outdir+'af3_results.tsv', sep='\t', index=False)
    
    return results
        
######################################################################################88
######################################################################################88
######################################################################################88

if __name__ == '__main__':
    targets = pd.read_table(
        '/home/pbradley/csdat/tcrpepmhc/amir/run506_A0201_HMTEVVRHC_pool.tsv'
    ).head(5)

    results = run_sasas_and_contacts(targets, outprefix='./tmp123')
    print(results)


    exit()
if __name__ == '__main__':

    pdbids = ['3i6g','6ss8']
    # pdbids = ['7rrg','9pap']

    for pdbid in pdbids:
        fname, hotspot_string = setup_rf_diff_pmhc_template(pdbid)
        print('hotspot_string:', pdbid, hotspot_string)
    sys.exit()

if __name__ == '__main__':
    results = pd.read_table(
        '/home/pbradley/csdat/tcrpepmhc/amir/run506_A0201_HMTEVVRHC_pool.tsv')
    results = results.head(1)
    #results = results.head(20)
    if results.targetid.value_counts().max()>1:
        results['targetid'] = [f'{x}_{i}' for i,x in enumerate(results.targetid)]

    df = run_mpnn(
        results, './tmptest37b',
        num_mpnn_seqs=5,
        #sort_by_peptide_probs=True,
        #sort_by_mpnn_score=True,
        sort_by_strength=True,
        pepspec_optimize=False,
        verbose=True,
        save_sorted_chainseqs=True,
    )

    print(df.iloc[0])
    print(df.iloc[0].sorted_chainseqs)
    exit()

if __name__ == '__main__':
    results = pd.read_table(
        '/home/pbradley/csdat/tcrpepmhc/amir/run506_A0201_HMTEVVRHC_pool.tsv')
    #results = results.head(3)
    results = results.head(20)
    if results.targetid.value_counts().max()>1:
        results['targetid'] = [f'{x}_{i}' for i,x in enumerate(results.targetid)]

    df = run_mpnn(
        results, './tmptest36b',
        num_mpnn_seqs=20,
        sort_by_peptide_probs=True,
        verbose=True,
    )

    exit()

if __name__ == '__main__':
    results = pd.read_table('/home/pbradley/csdat/tcrpepmhc/amir/run418_run419_models.tsv')
    results = results.head(3)
    #results = results.head(20)

    df = run_mpnn_peptide_probs(
        results, './tmptest36',
        num_mpnn_seqs=3,
    )


    exit()

if __name__ == '__main__':

    pdbids = ['3qdg', '5bs0', '7ow6']

    for pdbid in pdbids:
        fname, design_loops = setup_rf_diff_tcr_template(pdbid)
        print('design_loops:', pdbid, design_loops)



if __name__ == '__main__':
    results = pd.read_table('/home/pbradley/csdat/tcrpepmhc/amir/run474_results.tsv')
    results = results.head(1)

    df = run_mpnn(results, './tmptest', num_mpnn_seqs=20, sort_by_strength=True,
                  verbose=True)#, dry_run=True)

    exit()

if __name__ == '__main__':
    from glob import glob
    import random

    fname = '/home/pbradley/csdat/tcrpepmhc/amir/slurm/tmp.tsv'
    df = pd.read_table(fname)

    results = run_rosetta_relax(df, './tmptestrr')

    exit()

if __name__ == '__main__':
    from glob import glob
    import random

    fname = ('/home/pbradley/csdat/tcrpepmhc/amir/abi/'
             'compiled_metrics_filtered_20th_Feb_2024.csv')
    df = pd.read_csv(fname)
    df.drop_duplicates('pdbfile')
    pdbdir = '/home/pbradley/csdat/tcrpepmhc/amir/from_abi2/'
    df.pdbfile = pdbdir + df.pdbfile.map(basename)
    df['pmhc_pdbid'] = df.target_pdb.map(basename).str.slice(0,4)
    df['framework_pdbid'] = df.framework_pdb.map(basename).str.slice(0,4)
    mask = df.pdbfile.map(exists)
    assert all(mask)

    df = df.sample(n=30)

    dfl = []
    for _,l in df.iterrows():
        print('read:', l.pdbfile)
        pose = td2.pdblite.pose_from_pdb(l.pdbfile)
        cs = pose['chainseq'].split('/')
        tcra_seq, tcrb_seq = cs[0:2]
        dfl.append(dict(
            organism = 'human',
            pmhc_pdbid = l.pmhc_pdbid,
            framework_pdbid = l.framework_pdbid,
            tcra_seq=tcra_seq,
            tcrb_seq=tcrb_seq,
        ))
    tcr_db = pd.DataFrame(dfl)
    targets = setup_for_alphafold_simple(tcr_db, './tmptest11/')


    if 0:
        pdbfiles = glob(
            '/home/pbradley/csdat/tcrpepmhc/amir/abi/samples_tcr_5brz_cond0_??.pdb')
        assert len(pdbfiles) == 3

        dfl = []
        for pdbfile in pdbfiles:
            pose = td2.pdblite.pose_from_pdb(pdbfile)
            cs = pose['chainseq'].split('/')
            tcra_seq, tcrb_seq = cs[0:2]
            dfl.append(dict(
                organism = 'human',
                pmhc_pdbid = '5brz',
                framework_pdbid = '5brz',
                tcra_seq=tcra_seq,
                tcrb_seq=tcrb_seq,
            ))

        tcr_db = pd.DataFrame(dfl)

        targets = setup_for_alphafold_simple(tcr_db, './tmptest11/')

    sys.exit()

if __name__ == '__main__':
    pmhcs = pd.DataFrame([dict(
        organism = 'human',
        mhc_class = 1,
        pdbfile = '/home/pbradley/csdat/tcrpepmhc/amir/A2-PAP.pdb',
        pdbid = 'a2pp',
    )])
    extra_pmhc_templates = setup_extra_pmhc_templates(pmhcs, 'tmptest')
    print(extra_pmhc_templates.iloc[0])
    exit()


if __name__ == '__main__':

    pdbids = ['1oga','3o4l','3gsn']

    for pdbid in pdbids:
        fname, design_loops = setup_rf_diff_tcr_template(pdbid)
        print('design_loops:', pdbid, design_loops)


        fname, hotspot_string = setup_rf_diff_pmhc_template(pdbid)
        print('hotspot_string:', pdbid, hotspot_string)



